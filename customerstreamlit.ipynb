{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9ad6a55-ba5e-4190-a3e0-95875a00562b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 22:49:55.891 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-28 22:49:55.893 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-28 22:49:56.736 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2026-01-28 22:49:56.737 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-28 22:49:56.738 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-28 22:49:56.739 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-28 22:49:56.740 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-28 22:49:56.741 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-28 22:49:56.813 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-28 22:49:56.814 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-28 22:49:56.814 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-28 22:49:56.815 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-28 22:49:56.815 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-28 22:49:56.816 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-28 22:49:56.817 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-28 22:49:56.818 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-28 22:49:56.819 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Customer Segmentation Streamlit App\n",
    "\n",
    "# Importing required libraries\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Page Configuration\n",
    "st.set_page_config(page_title=\"Customer Segmentation\", layout=\"wide\")\n",
    "\n",
    "st.title(\"üìä Customer Segmentation Using Behavioral Patterns\")\n",
    "st.write(\n",
    "    \"This application uses a pre-trained K-Means model to segment customers \"\n",
    "    \"based on spending behavior and purchase patterns.\"\n",
    ")\n",
    "\n",
    "# Load Pickle Files (Model & Scaler)\n",
    "# Loading trained K-Means model\n",
    "with open(\"kmeans_model.pkl\", \"rb\") as f:\n",
    "    kmeans_model = pickle.load(f)\n",
    "\n",
    "# Loading scaler used during training\n",
    "with open(\"scaler.pkl\", \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "# Dataset Uploading\n",
    "uploaded_file = st.file_uploader(\n",
    "    \"Upload Customer Dataset (CSV or Excel)\",\n",
    "    type=[\"csv\", \"xlsx\"]\n",
    ")\n",
    "\n",
    "if uploaded_file is not None:\n",
    "\n",
    "    # Reading dataset\n",
    "    if uploaded_file.name.endswith(\".csv\"):\n",
    "        df = pd.read_csv(uploaded_file)\n",
    "    else:\n",
    "        df = pd.read_excel(uploaded_file)\n",
    "\n",
    "    st.subheader(\"üìÑ Dataset Preview\")\n",
    "    st.dataframe(df.head())\n",
    "\n",
    "    # Data Cleaning\n",
    "    # Handling missing Income values\n",
    "    df['Income'].fillna(df['Income'].median(), inplace=True)\n",
    "\n",
    "    # Feature Engineering\n",
    "    # Creating Total_Spend feature\n",
    "    df['Total_Spend'] = (\n",
    "        df['MntWines'] +\n",
    "        df['MntMeatProducts'] +\n",
    "        df['MntFishProducts'] +\n",
    "        df['MntSweetProducts'] +\n",
    "        df['MntGoldProds']\n",
    "    )\n",
    "\n",
    "    # Creating Total_Purchases feature\n",
    "    df['Total_Purchases'] = df['NumWebPurchases'] + df['NumStorePurchases']\n",
    "\n",
    "    # Feature Selection\n",
    "    features = df[\n",
    "        ['Income', 'Recency', 'Total_Spend', 'Total_Purchases']\n",
    "    ]\n",
    "\n",
    "    # Feature Scaling (Using Loaded Scaler)\n",
    "    scaled_features = scaler.transform(features)\n",
    "\n",
    "    # Predicting Clusters Using Pickle Model\n",
    "    df['Cluster'] = kmeans_model.predict(scaled_features)\n",
    "\n",
    "    # Cluster Summary\n",
    "    st.subheader(\"üìå Cluster Summary (Average Values)\")\n",
    "\n",
    "    cluster_summary = df.groupby('Cluster')[\n",
    "        ['Income', 'Total_Spend', 'Recency', 'Total_Purchases']\n",
    "    ].mean()\n",
    "\n",
    "    st.dataframe(cluster_summary)\n",
    "\n",
    "    # PCA for Cluster Visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_data = pca.fit_transform(scaled_features)\n",
    "\n",
    "    pca_df = pd.DataFrame({\n",
    "        'PC1': pca_data[:, 0],\n",
    "        'PC2': pca_data[:, 1],\n",
    "        'Cluster': df['Cluster']\n",
    "    })\n",
    "\n",
    "    # Plotting Clusters\n",
    "    st.subheader(\"üìà Customer Segments (PCA Visualization)\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=pca_df,\n",
    "        x='PC1',\n",
    "        y='PC2',\n",
    "        hue='Cluster',\n",
    "        palette='tab10',\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"Customer Segments Visualized Using PCA\")\n",
    "    ax.set_xlabel(\"Principal Component 1\")\n",
    "    ax.set_ylabel(\"Principal Component 2\")\n",
    "\n",
    "    st.pyplot(fig)\n",
    "    \n",
    "    # Download Final Clustered Dataset\n",
    "    st.subheader(\"‚¨áÔ∏è Download Clustered Dataset\")\n",
    "\n",
    "    csv = df.to_csv(index=False).encode(\"utf-8\")\n",
    "\n",
    "    st.download_button(\n",
    "        label=\"Download Clustered Data\",\n",
    "        data=csv,\n",
    "        file_name=\"clustered_customers.csv\",\n",
    "        mime=\"text/csv\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    st.info(\"Please upload a customer dataset to start segmentation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed5787-65c6-41f8-85b5-dd4413b6f8b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
